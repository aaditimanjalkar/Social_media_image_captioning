{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90e025b",
   "metadata": {},
   "source": [
    "# Identification of Different Medicinal Plants/Raw materials through Image Processing Using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd840f18",
   "metadata": {},
   "source": [
    "In a project aiming to identify medicinal plants and raw materials through image processing with machine learning, the data preparation approach has been enhanced. Convolutional Neural Networks (CNNs) are incorporated to improve image analysis.\n",
    "\n",
    "This code gathers images from a source folder and stores them in a separate destination folder. What sets this approach apart is the utilization of CNNs, enabling the project to discern intricate image details. This analysis enhances plant identification precision through machine learning techniques.\n",
    "\n",
    "By employing CNNs, the dataset becomes better suited for training and feature extraction, ultimately improving the accuracy of the plant identification process. This step signifies a critical advancement in the project's capabilities, enabling more reliable and detailed results when identifying different medicinal plants and raw materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19da3f",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31dec30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow.compat.v2 as tf\n",
    "import matplotlib.pyplot  as plt\n",
    "import cv2\n",
    "import PIL\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import tensorflow\n",
    "# import tensorflow.compat.v2 as tf\n",
    "# import matplotlib.pyplot as plt\n",
    "# import cv2\n",
    "# import os\n",
    "# import numpy as np\n",
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "# from tensorflow.keras.optimizers import RMSprop\n",
    "# from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# import os\n",
    "# import random\n",
    "# import shutil\n",
    "# from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc3da9",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd655c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Combined\"\n",
    "train_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Train\"\n",
    "validation_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Val\"\n",
    "test_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Test\"\n",
    "# train_ratio = 0.8\n",
    "\n",
    "# os.makedirs(train_dataset, exist_ok=True)\n",
    "# os.makedirs(validation_dataset, exist_ok=True)\n",
    "# os.makedirs(test_dataset, exist_ok=True)\n",
    "\n",
    "# for class_name in os.listdir(src_dataset):\n",
    "#     class_src = os.path.join(src_dataset, class_name)\n",
    "#     class_train = os.path.join(train_dataset, class_name)\n",
    "#     class_validation = os.path.join(validation_dataset, class_name)\n",
    "#     class_test = os.path.join(test_dataset, class_name)\n",
    "\n",
    "#     os.makedirs(class_train, exist_ok=True)\n",
    "#     os.makedirs(class_validation, exist_ok=True)\n",
    "#     os.makedirs(class_test, exist_ok=True)\n",
    "\n",
    "#     files = os.listdir(class_src)\n",
    "#     random.shuffle(files)\n",
    "\n",
    "#     split_index_train = int(train_ratio * len(files))\n",
    "#     split_index_validation = int((train_ratio + 0.1) * len(files))\n",
    "\n",
    "#     train_files = files[:split_index_train]\n",
    "#     validation_files = files[split_index_train:split_index_validation]\n",
    "#     test_files = files[split_index_validation:]\n",
    "\n",
    "#     for file in train_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_train, file))\n",
    "\n",
    "#     for file in validation_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_validation, file))\n",
    "\n",
    "#     for file in test_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_test, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b05b86",
   "metadata": {},
   "source": [
    "## Batch Image Resizing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814284e",
   "metadata": {},
   "source": [
    "### 1. For Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f371472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "main_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Train\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\TrainResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b51fe0",
   "metadata": {},
   "source": [
    "### 2. For Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "05cd7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Val\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\ValResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ecac8",
   "metadata": {},
   "source": [
    "### 3. For Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb128a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder =  r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Test\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\TestResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f336b4e",
   "metadata": {},
   "source": [
    "## Rescaling and Data Augmentation for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceba7a",
   "metadata": {},
   "source": [
    "In an image classification project, data is optimized for machine learning by rescaling images for consistency and applying data augmentation for improved model robustness. These techniques enhance the dataset for accurate identification of medicinal plants and raw materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0908259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12276 images belonging to 26 classes.\n",
      "Found 1534 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "batch_size = 11\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a85dff",
   "metadata": {},
   "source": [
    "## Creating a Convolutional Neural Network (CNN) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71608c",
   "metadata": {},
   "source": [
    "This code segment outlines the creation of a Convolutional Neural Network (CNN) model. CNNs are essential for image-related tasks, and this model is being designed for image classification in our project. The model architecture includes convolutional and pooling layers, followed by fully connected layers, culminating in an output layer for classification. This foundational step lays the groundwork for effective image recognition in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b669847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                           input_shape=(256, 256, 3), padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5), \n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2015280",
   "metadata": {},
   "source": [
    "## Customizing Learning Rate for Adam Optimizer in a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "eeb80bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d56df",
   "metadata": {},
   "source": [
    "## Training a Keras Model on Image Data Using Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e93c4b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m68\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\finale\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\finale\\lib\\site-packages\\keras\\utils\\image_utils.py:414\u001b[0m, in \u001b[0;36mload_img\u001b[1;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m    412\u001b[0m     color_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import PIL.Image. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use of `load_img` requires PIL.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io\u001b[38;5;241m.\u001b[39mBytesIO):\n\u001b[0;32m    418\u001b[0m     img \u001b[38;5;241m=\u001b[39m pil_image\u001b[38;5;241m.\u001b[39mopen(path)\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "import PIL\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=68,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c66681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d070aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081172a",
   "metadata": {},
   "source": [
    "## Evaluating a Keras Model on a Test Dataset Using a Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f651070",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb44405f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b0948e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('PROJECT_MODEL_PICKEL-trial_and_error111111','wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbe1c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"my_name_is_lakhan_prime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3de8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('My_name_is_lakhan_prime_1','wb') as f:\n",
    "    pickle.dump(model,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ef6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the next version number\n",
    "model_version = max([int(i) for i in os.listdir(\"C:/Users/Admin/model_training_ka_data\") + [0]]) + 1\n",
    "\n",
    "# Save the model with the specified name and version number\n",
    "model.save(f\"C:/Users/Admin/model_training_ka_data/{model_name}_v{model_version}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finale",
   "language": "python",
   "name": "finale"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
